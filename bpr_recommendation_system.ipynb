{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CgAIZqD9Pvt3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import path\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "from typing import Dict\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Input, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "KYk1_ENUPvt9",
    "outputId": "6fb5bda4-a468-4b9c-9ab3-ff5e0812d07a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x1kO7wqsPvuA"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_DATA = 'data'\n",
    "DIR_MODEL = 'models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sZX_fgW-PvuE"
   },
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 78
    },
    "colab_type": "code",
    "id": "r1XaSACWPvuF",
    "outputId": "c63dfe15-6a25-4744-96be-c7e7317aebc3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "      <th>rating</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2783</td>\n",
       "      <td>1253</td>\n",
       "      <td>5</td>\n",
       "      <td>2783_1253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  movie  rating         id\n",
       "0  2783   1253       5  2783_1253"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = pd.read_csv(path.join(DIR_DATA, 'training_ratings_for_kaggle_comp.csv'))\n",
    "df_full.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8VuGs1IaPvuH"
   },
   "source": [
    "### Build the references\n",
    "\n",
    "I'm planning to use the `Embedding` layer, so I need to link real ids of the users and movies to the order ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "OoDabTupFip9",
    "outputId": "ad20f816-3b5c-45ee-863f-94e8dcbe9634"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3939, 3940, 3941, 3942, 3943, 3945, 3946, 3947, 3948, 3952]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(df_full.movie.unique())[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "k3QPjga0Fijo",
    "outputId": "a183b3ff-a383-4028-c627-da6e8c957230"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2783, 2784, 2785, 2786, 2787, 2788, 2789, 2790, 2791, 2792]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(df_full.user.unique())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C6nLiZbhPvuI"
   },
   "outputs": [],
   "source": [
    "unique_users = df_full.user.unique()\n",
    "user_ids = dict(zip(unique_users, np.arange(unique_users.shape[0], dtype=np.int32)))\n",
    "\n",
    "unique_movies = df_full.movie.unique()\n",
    "movie_ids = dict(zip(unique_movies, np.arange(unique_movies.shape[0], dtype=np.int32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 78
    },
    "colab_type": "code",
    "id": "olyJ8mNSPvuK",
    "outputId": "f1a914c9-9813-46d9-86aa-9407f02654aa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "      <th>rating</th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2783</td>\n",
       "      <td>1253</td>\n",
       "      <td>5</td>\n",
       "      <td>2783_1253</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  movie  rating         id  user_id  movie_id\n",
       "0  2783   1253       5  2783_1253        0         0"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full['user_id'] = df_full.user.apply(lambda u: user_ids[u])\n",
    "df_full['movie_id'] = df_full.movie.apply(lambda m: movie_ids[m])\n",
    "\n",
    "df_full.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "98tiF_JUPvuM"
   },
   "source": [
    "### Train/test split\n",
    "\n",
    "Here the main idea is to extract some movies for users who have a big amount of positive reviews into the test subtest. I extract 2 movies for each user who have more than 20 positive reviews. This test subset won't be used during training, but these movies should appear in the top recommendations for each user accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CaJd-1ZLPvuN"
   },
   "source": [
    "#### Test subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "h6CFhFQ1PvuO",
    "outputId": "9c2470e8-582a-488d-bbd3-fb3bc360ca55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3225, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_test = df_full[df_full.rating > 4]\n",
    "tmp_test = tmp_test.groupby('user').movie.count().reset_index()\n",
    "tmp_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vAFnOarcPvuQ",
    "outputId": "53d89979-e763-4784-c9a5-055ccf4c73cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3500, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions = (df_full.user.isin(tmp_test[tmp_test.movie > 20].user)) & (df_full.rating > 4)\n",
    "df_test = df_full[conditions].groupby('user').head(2).reset_index()\n",
    "\n",
    "del df_test['index']\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 78
    },
    "colab_type": "code",
    "id": "8pyEqgdzITb5",
    "outputId": "10a7a835-76d3-4a9c-bc58-8e7024a6c803"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>[221, 222]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id    movie_id\n",
       "0        3  [221, 222]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_test = df_test.groupby('user_id').movie_id.agg(list).reset_index()\n",
    "\n",
    "ground_truth_test.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H5Ur3JyDPvuS"
   },
   "source": [
    "#### Training subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "P413xozyPvuS",
    "outputId": "327105d0-5fa4-4cb4-8ded-030502af6558"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(496600, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.concat([df_full, df_test]).drop_duplicates(keep=False)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 78
    },
    "colab_type": "code",
    "id": "oD6QmfCVIOib",
    "outputId": "10a5b7f4-50ea-4e88-f754-ff99b316346e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 10, 13, 14, 16, 18, 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                           movie_id\n",
       "0        0  [0, 1, 2, 3, 4, 5, 6, 7, 10, 13, 14, 16, 18, 2..."
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The assumption is that the recommendations should as many as possible high ranked movies \n",
    "# that a specific user has already watched.\n",
    "\n",
    "ground_truth_train = df_train[df_train.rating > 3].groupby('user_id').movie_id.agg(list).reset_index()\n",
    "\n",
    "ground_truth_train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aJghgU6vPvuW"
   },
   "source": [
    "### Building triplets\n",
    "\n",
    "Bayers Personalized Ranking requires for the training a triplet of the user, positive item and negative item. For each user, I create a pair of each positive ranked movie (the rank is higher than 3) with all negative movies (the rank is equal  3 and lower than)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 48
    },
    "colab_type": "code",
    "id": "o8pe4UuCPvuX",
    "outputId": "a8da398b-6be8-4df7-9e21-b41cc0f7a026"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>positive_m_id</th>\n",
       "      <th>negative_m_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [user_id, positive_m_id, negative_m_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_triplest = pd.DataFrame(columns=['user_id', 'positive_m_id', 'negative_m_id'])\n",
    "df_triplest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "h7U9tvfME9Qk",
    "outputId": "4d744904-9c9b-4c15-c949-943fb7dd8fe1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3255/3255 [00:52<00:00, 61.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 24s, sys: 20.9 s, total: 1min 45s\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data = []\n",
    "users_without_data = []\n",
    "\n",
    "for user_id in tqdm(df_train.user_id.unique()):\n",
    "    positive_movies = df_train[(df_train.user_id == user_id) & (df_train.rating > 3)].movie_id.values\n",
    "    negative_movies = df_train[(df_train.user_id == user_id) & (df_train.rating <= 3)].movie_id.values\n",
    "\n",
    "    if negative_movies.shape[0] == 0 or positive_movies.shape[0] == 0:\n",
    "        users_without_data.append(user_id)\n",
    "        continue\n",
    "\n",
    "\n",
    "    for positive_movie in positive_movies:\n",
    "        for negative_movie in negative_movies:\n",
    "            data.append({'user_id': user_id, 'positive_m_id': positive_movie, 'negative_m_id': negative_movie})\n",
    "\n",
    "df_triplest = df_triplest.append(data, ignore_index=True)\n",
    "# df_triplest.to_csv(path.join(DIR_DATA, 'triplets.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "MccQ8Z_OPvub",
    "outputId": "b188b6ff-0eaf-4765-d37d-3aea47d31945"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37621280, 3), (496600, 6))"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_triplest.shape, df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SnL1T_B-Pvud"
   },
   "source": [
    "### BPR NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "sU-e4ufEPvue",
    "outputId": "f8f48911-8405-4306-c4aa-311b500aaa88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3255, 3551)"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users = unique_users.shape[0]\n",
    "num_items = unique_movies.shape[0]\n",
    "\n",
    "num_users, num_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dQZftSXIPvuh"
   },
   "outputs": [],
   "source": [
    "unique_movie_ids = list(df_full.movie_id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uXVTD3WoPvuj"
   },
   "source": [
    "### Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S0oVFCYKPvuk"
   },
   "outputs": [],
   "source": [
    "def bpr_predict(model: Model, user_id: int, item_ids: list, user_layer='user_embedding', item_layer='item_embedding'):\n",
    "    \"\"\"\n",
    "    Predict by multiplication user vector by item matrix\n",
    "    \n",
    "    :return: list of the scores\n",
    "    \"\"\"\n",
    "    user_vector = model.get_layer(user_layer).get_weights()[0][user_id]\n",
    "    item_matrix = model.get_layer(item_layer).get_weights()[0][item_ids]\n",
    "\n",
    "    scores = (np.dot(user_vector, item_matrix.T))\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9kVjqqGcPvus"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def identity_loss(_, y_pred):\n",
    "    return tf.math.reduce_mean(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NXvCrzd6Pvut"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def bpr_triplet_loss(X: dict):\n",
    "    \"\"\"\n",
    "    Calculate triplet loss - as higher the difference between positive interactions\n",
    "    and negative interactions as better\n",
    "\n",
    "    :param X: X contains the user input, positive item input, negative item input\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    positive_item_latent, negative_item_latent, user_latent = X\n",
    "\n",
    "    positive_interactions = tf.math.reduce_sum(tf.math.multiply(user_latent, positive_item_latent), axis=-1, keepdims=True)\n",
    "    negative_interactions = tf.math.reduce_sum(tf.math.multiply(user_latent, negative_item_latent), axis=-1, keepdims=True)\n",
    "\n",
    "    return tf.math.subtract(tf.constant(1.0), tf.sigmoid(tf.math.subtract(positive_interactions, negative_interactions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LSOtSLEfPvuv"
   },
   "outputs": [],
   "source": [
    "def out_shape(shapes):\n",
    "    return shapes[0]\n",
    "    \n",
    "\n",
    "def build_model(num_users: int, num_items: int, latent_dim: int) -> Model:\n",
    "    \"\"\"\n",
    "    Build a model for Bayesian personalized ranking\n",
    "\n",
    "    :param num_users: a number of the unique users\n",
    "    :param num_items: a number of the unique movies\n",
    "    :param latent_dim: vector length for the latent representation\n",
    "    :return: Model\n",
    "    \"\"\"\n",
    "    user_input = Input((1,), name='user_input')\n",
    "\n",
    "    positive_item_input = Input((1,), name='positive_item_input')\n",
    "    negative_item_input = Input((1,), name='negative_item_input')\n",
    "    # One embedding layer is shared between positive and negative items\n",
    "    item_embedding_layer = Embedding(num_items, latent_dim, name='item_embedding', input_length=1)\n",
    "\n",
    "    positive_item_embedding = Flatten()(item_embedding_layer(positive_item_input))\n",
    "    negative_item_embedding = Flatten()(item_embedding_layer(negative_item_input))\n",
    "\n",
    "    user_embedding = Embedding(num_users, latent_dim, name='user_embedding', input_length=1)(user_input)\n",
    "    user_embedding = Flatten()(user_embedding)\n",
    "\n",
    "    triplet_loss = Lambda(bpr_triplet_loss, output_shape=out_shape)([positive_item_embedding,\n",
    "                                                             negative_item_embedding,\n",
    "                                                             user_embedding])\n",
    "\n",
    "    model = Model(inputs=[positive_item_input, negative_item_input, user_input], outputs=triplet_loss)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NYFjol0MPvuw"
   },
   "outputs": [],
   "source": [
    "latent_dim = 350\n",
    "batch_size = 256\n",
    "num_epochs = 1\n",
    "lr = 0.001\n",
    "\n",
    "model = build_model(num_users, num_items, latent_dim)\n",
    "model.compile(loss=identity_loss, optimizer=Adam(learning_rate=lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "ysd-DgIBPvuy",
    "outputId": "24a42844-b257-4268-a4f2-4c21d3f3cd6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2,382,100.0\n",
      "Trainable number of parameters: 2,382,100\n",
      "Non-trainable number of parameters: 0.0\n",
      "Training data length: 37,621,280\n"
     ]
    }
   ],
   "source": [
    "trainable_count = np.sum([K.count_params(w) for w in model.trainable_weights])\n",
    "non_trainable_count = np.sum([K.count_params(w) for w in model.non_trainable_weights])\n",
    "\n",
    "print('Total number of parameters: {:,}'.format(trainable_count + non_trainable_count))\n",
    "print('Trainable number of parameters: {:,}'.format(trainable_count))\n",
    "print('Non-trainable number of parameters: {:,}'.format(non_trainable_count))\n",
    "\n",
    "print('Training data length: {:,}'.format(df_triplest.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "Uzy0xBkdKCp0",
    "outputId": "aa36d931-b97a-4d4a-8a02-d4503358f21c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37621280 samples\n",
      "37621280/37621280 [==============================] - 1240s 33us/sample - loss: 0.0078\n",
      "CPU times: user 2h 16min 5s, sys: 28min 48s, total: 2h 44min 53s\n",
      "Wall time: 21min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X = {\n",
    "    'user_input': tf.convert_to_tensor(df_triplest.user_id),\n",
    "    'positive_item_input': tf.convert_to_tensor(df_triplest.positive_m_id),\n",
    "    'negative_item_input': tf.convert_to_tensor(df_triplest.negative_m_id)\n",
    "}\n",
    "\n",
    "model.fit(X, \n",
    "          tf.ones(df_triplest.shape[0]), \n",
    "          batch_size=batch_size,\n",
    "          epochs=num_epochs)\n",
    "\n",
    "# model.save(path.join(DIR_MODEL, 'model.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3E5euOhHPvu2"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9VeMTpZH7_op"
   },
   "outputs": [],
   "source": [
    "def full_auc(model: Model, ground_truth: Dict[int, list], items: list) -> float:\n",
    "    \"\"\"\n",
    "    Measure AUC for model and ground truth for all items\n",
    "    \n",
    "    :param model: \n",
    "    :param ground_truth: dictionary of the users and the high ranked movies for the specific user\n",
    "    :param items: a list of the all available movies\n",
    "    :return: AUC\n",
    "    \"\"\"\n",
    "\n",
    "    number_of_items = len(items)\n",
    "    scores = []\n",
    "\n",
    "    for user_id, true_item_ids in ground_truth:\n",
    "        predictions = bpr_predict(model, user_id, items)\n",
    "        grnd = np.zeros(number_of_items, dtype=np.int32)\n",
    "\n",
    "        for p in true_item_ids:\n",
    "            index = items.index(p)\n",
    "            grnd[index] = 1\n",
    "\n",
    "        if true_item_ids:\n",
    "            scores.append(roc_auc_score(grnd, predictions))\n",
    "\n",
    "    return sum(scores) / len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4I_FsXW_7_lJ"
   },
   "outputs": [],
   "source": [
    "def mean_average_precision_k(model: Model, \n",
    "                           ground_truth: Dict[int, list], \n",
    "                           items: list, \n",
    "                           k=100) -> float:\n",
    "    \"\"\"\n",
    "    Calculate mean eavarage precission per user\n",
    "    \n",
    "    :param model: \n",
    "    :param ground_truth: dictionary of the users and the high ranked movies for the specific user\n",
    "    :param items: a list of the all available movies\n",
    "    :param k: top N recommendations per user\n",
    "    :return: mean eavarage precission\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "\n",
    "    for user, actual in ground_truth:\n",
    "        predictions = bpr_predict(model, user, items)\n",
    "        predictions = dict(zip(items, predictions))\n",
    "        predictions = sorted(predictions.items(), key=lambda kv: kv[1], reverse=True)[:k]\n",
    "        predictions = list(OrderedDict(predictions).keys())\n",
    "\n",
    "        score = 0.0\n",
    "        num_hits = 0.0\n",
    "\n",
    "        for i, p in enumerate(predictions):\n",
    "            if p in actual:\n",
    "                num_hits += 1.0\n",
    "                score += num_hits / (i + 1.0)\n",
    "\n",
    "        score = score / min(len(actual), k)\n",
    "        scores.append(score)\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bZozbt1nPvu3"
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "7lPkYUTaPvu3",
    "outputId": "69da7990-dce5-4583-f54d-1b32fe684cb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC train: 0.9552896655958131\n"
     ]
    }
   ],
   "source": [
    "print(f'AUC train: {full_auc(model, ground_truth_train.values, unique_movie_ids)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "x-Xyb27QPvu5",
    "outputId": "85ad223b-fdce-4850-d1b9-76c8bde6f124"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean average precision train: 0.3135110111288244\n"
     ]
    }
   ],
   "source": [
    "print(f'Mean average precision train: {mean_average_precision_k(model, ground_truth_train.values, unique_movie_ids)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zCk6i4eRPvu7"
   },
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Y4SDT7gEPvu-",
    "outputId": "7205f055-75e2-4bd9-aa30-15affb8242cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC test: 0.7855946544298201\n"
     ]
    }
   ],
   "source": [
    "print(f'AUC test: {full_auc(model, ground_truth_test.values, unique_movie_ids)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "FtyRNxBePvvA",
    "outputId": "d3e41529-7011-4a8d-febb-c9aa9502e603"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean average precision test: 0.014455187878782139\n"
     ]
    }
   ],
   "source": [
    "print(f'Mean average precision test: {mean_average_precision_k(model, ground_truth_test.values, unique_movie_ids)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4DpYGaZEPvvL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "bpr_recommendation_system.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
